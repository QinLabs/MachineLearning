{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fb8b2ce-51db-4f8e-9006-a2628dc1ac27",
   "metadata": {},
   "source": [
    "<font color=black size=5>Part 1 Import Libraries</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "688372ab-f37a-4740-b224-94b4705ea5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch                                  # Torch for Pytorch base (for deep learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4f6a504-2614-47d9-9afc-48247186c8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1\n",
    "import numpy as np                            # numpy for numerical computation\n",
    "import torchvision                            # TorchVision for image processing\n",
    "import matplotlib.pyplot as plt               # Plotting tools\n",
    "from time import time                         # Timing tools\n",
    "from torchvision import datasets, transforms  # Import dataset and transform functions\n",
    "from torch import nn, optim                   # Import neural network and optimization classes\n",
    "import cv2  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5eb8a9-78c3-4e50-a293-b4a667afc0b3",
   "metadata": {},
   "source": [
    "<font color=black size=5>Part 2 Data Pre-processing Transform</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5ad95b3-d7ed-4555-8569-4400887f5de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "# transform is a global class object that does the transform for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcd94e8-8b8a-4426-a530-706da788b3c7",
   "metadata": {},
   "source": [
    "<font color=black size=5>Part 3 Download Data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab3529e6-e759-46ae-88de-925b8bc079fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c85282ec6b9345d4b46f9d0d55f54bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ebc51b701a4f909fea32cd9a0fbb57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6434d88584440cf8ee702f8eaa99000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da039ab140942c9bfe5fada9b802930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download the training data and the validation data\n",
    "trainset    = datasets.MNIST('./MNIST/', download=True, train=True, transform=transform)\n",
    "valset      = datasets.MNIST('./MNIST/', download=True, train=False, transform=transform)\n",
    "\n",
    "# Define the loader that loads images into the correct format\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "valloader   = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Create iteration objection, images, and labels\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0e2f70-9eac-47f6-8fae-e6c1de9e62a7",
   "metadata": {},
   "source": [
    "<font color=black size=5>Part 4 Construct Your Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af1c7601-cce8-4722-9d41-f255b4c9a985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we construct the neural network. There is no training involved yet. We are only defining the model.\n",
    "input_size = 784\n",
    "hidden_sizes = [128, 64, 32]\n",
    "output_size = 10\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], hidden_sizes[2]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[2], output_size),\n",
    "                      nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f797031-3fea-4fda-9f55-a84d2cc033d7",
   "metadata": {},
   "source": [
    "<font color=black size=5>Part 5 Construct the training loss</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d8980fb-1c37-4825-93b5-d71767fc734a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logps = model(images)                 #log probabilities\n",
    "loss = criterion(logps, labels)       #calculate the NLL loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435c73a5-80b0-4634-b505-6c0845b9f7af",
   "metadata": {},
   "source": [
    "<font color=black size=5>Part 6 Main Training Loop</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b14a00a-2b18-4ac7-a581-edf8f2092347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Training loss: 0.8874483321711961\n",
      "Epoch 1 - Training loss: 0.30277637838681876\n",
      "\n",
      "Training Time (in minutes) = 4.545971580346426\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
    "time0 = time()\n",
    "epochs = 2\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        #This is where the model learns by backpropagating\n",
    "        loss.backward()\n",
    "        \n",
    "        #And optimizes its weights here\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(e, running_loss/len(trainloader)))\n",
    "print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602fe73b-7115-41a8-bd90-2811afece1d3",
   "metadata": {},
   "source": [
    "<font color=black size=5>Part 7 Testing</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a4f4a40-a563-4450-9a7c-e3e53bcb791b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Digit = 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(iter(valloader))\n",
    "img = images[0].view(1, 784)\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "ps = torch.exp(logps)\n",
    "probab = list(ps.numpy()[0])\n",
    "print(\"Predicted Digit =\", probab.index(max(probab)))\n",
    "plt.imshow(images[0].numpy().squeeze(), cmap='gray_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef594d0d-c6c1-48cf-b533-129c3a64b792",
   "metadata": {},
   "source": [
    "<font color=black size=5>Part 8 Testing</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63bf20ab-b65e-4d8f-a106-1980790c2047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using cv2.imread() method \n",
    "# # Using 0 to read image in grayscale mode \n",
    "# img = cv2.imread('digit_2.png', 0)  # You will need to change the filename\n",
    "# # resize image to 28x28\n",
    "# img = cv2.resize(img, (28,28),interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "# # flip the image color\n",
    "# # this is optional; and feel free to change it\n",
    "# for i in range(0,img.shape[0]):\n",
    "#   for j in range(0,img.shape[1]):\n",
    "#     if img[i,j]>125:\n",
    "#       img[i,j] = 0\n",
    "#     else:\n",
    "#       img[i,j] = 255 - img[i,j]\n",
    "\n",
    "# # plot the processed image\n",
    "# plt.imshow(img, cmap='gray_r')\n",
    "\n",
    "# # input the processed image to the network and make prediction\n",
    "# img = transform(img).view(1, 784)\n",
    "# with torch.no_grad():\n",
    "#     logps = model(img)\n",
    "# ps = torch.exp(logps)\n",
    "# probab = list(ps.numpy()[0])\n",
    "# print(\"Predicted Hand-written Digit =\", probab.index(max(probab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc009be-f383-4f12-8a36-16081e119149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649f9f45-0c9b-4340-8eea-c2f4f863d393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8439e2d1-b362-4ba7-8137-b7337f7a9dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f4518c-f5eb-45ec-ad12-d9b25cc780cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b4dcbf-bcb7-4d93-a267-ce706f53db13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
